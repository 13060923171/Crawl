# 如何创建一个最简单的爬虫

首先导入一些最常用的库，requests是用于请求,BeautifulSoup是用于解析页面

```python
import requests
from bs4 import BeautifulSoup
```

然后创建一个请求头，请求头的含义是为了伪装成一个浏览器，不然容易被系统检测出来是一个爬虫，然后就很容易被封IP，如何去寻找这些请求头，先打开浏览器，然后鼠标右键点击检查，然后在选项卡选择network，先刷新页面，然后选择第一个文件，在里面寻找你需要用到的信息，不过大多数信息没什么用，一般都是用到user-agent和cookie比较多。

```python
headers = {'ser-Agent':' Mozilla/5.0 (Windows NT 10.0; Win6'}
```

再者就是调用我们的库了

```python
#首先先是请求一个页面，并且用get函数来获取这个页面的信息
html = requests.get("https://weibo.com/ttarticle/p/show?id=2309404490834430001482",headers=headers)
#然后用我们的解析库来解析这个页面的内容，用文本的形式把这个页面的内容爬取下来
soup = BeautifulSoup(html.text,'lxml')
#最后就是用find_all打印这个页面的所有内容了
print(soup.find_all('a'))
```

